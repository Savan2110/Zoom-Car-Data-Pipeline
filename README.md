# ğŸš— ZoomCar Data Processing Pipeline

A data engineering project built with **Databricks, PySpark, and Delta Lake** to process ZoomCarâ€™s customer and booking data.  
This project demonstrates an **end-to-end ETL pipeline** including ingestion, transformation, and loading into target tables for analytics.

---

## ğŸ“¸ Project Snapshots
*(Upload your screenshots in the `images/` folder and replace below placeholders)*  

- ![Pipeline Architecture](<img width="1677" height="937" alt="pipeline" src="https://github.com/user-attachments/assets/d1dfac71-5b06-4632-8ae5-45be2d614c37" />)  
- ![Databricks Workflow](<img width="1677" height="930" alt="job_run" src="https://github.com/user-attachments/assets/1b166b9c-0fdc-4965-958f-8b16aa73ef8e" />)  
- ![Delta Table Output](<img width="1680" height="858" alt="target_bookings_delta" src="https://github.com/user-attachments/assets/7202eb11-b4b8-4c36-8feb-722bbf420f53" /><img width="1677" height="897" alt="target_customers_delta" src="https://github.com/user-attachments/assets/2d9dca97-e725-4f2e-91dc-8ce0609c2525" />)  

---

## ğŸ” Overview

This pipeline processes raw JSON booking and customer data from ZoomCar into clean, optimized Delta tables ready for analytics.  

Key highlights:
- Raw data ingestion from JSON files (simulated as if coming from ADLS/Blob storage).
- Data cleaning and standardization with PySpark.
- **Delta Lake merge operations** to handle inserts, updates, and deletes (SCD-Type 2 style).
- Automated execution using **Databricks Jobs & Workflows**.
- Organized repository for reproducibility.

---

## ğŸ§° Tech Stack

- **Databricks** â†’ notebook-based development & orchestration  
- **PySpark** â†’ distributed data processing  
- **Delta Lake** â†’ ACID-compliant data storage  
- **Azure Data Lake Storage (ADLS)** â†’ raw & processed data layers  

---

## ğŸ“‚ Repository Structure

```plaintext
zoom-car-data-pipeline/
â”œâ”€â”€ data/              # sample or raw input files
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ notebooks/         # exported Databricks notebooks
â”‚   â”œâ”€â”€ customers.ipynb
â”‚   â”œâ”€â”€ bookings.ipynb
â”‚   â””â”€â”€ merge.ipynb
â”œâ”€â”€ src/               # optional reusable PySpark scripts
â”œâ”€â”€ images/            # screenshots (pipeline, jobs, outputs)
â”œâ”€â”€ requirements.txt   # dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
